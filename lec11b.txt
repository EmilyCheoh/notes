Implementing Union-Find
-----------------------

Union-Find ADT

interface UNION_FIND:
    # Returns the number of objects in the union-find. The objects
    # are the natural numbers 0, 1, ..., `self.len() - 1`.
    def len(self) -> nat?

    # Unions the set containing `a` with the set containing `b`.
    def union(self, a: nat?, b: nat?) -> VoidC

    # Returns whether `a` and `b` are in the same set?
    def same_set?(self, a: nat?, b: nat?) -> bool?

How might we implement this efficiently? We’re going to pursue a set of
approaches that consider each disjoint set to have some distinguished
“ID” element that is chosen arbitrarily from its elements. Then we add
an operation:

    # For any object `a`, gives back its ID element.
    def find(self, a: nat?) -> nat?

Then

    def same_set?(self, a: nat?, b: nat?) -> bool?:
        self.find(a) == self.find(b)

How might we implement these efficiently?

Solution 1: Eager (quick find)

Each set has some arbitrary element of the set as its ID. Keep a vector
of size n mapping each element to the ID of its set. So `find` is easy.
How about `union`? (O(n). How?)

This is too slow: O(EV) for |E| unions on |V| objects.

Solution 2: Lazy (quick union!)

Keep a vector `id` of size n representing a parent-pointer forest of
vertices. That is, this forest (representing two disjoint sets)

      0         5
    / | \       |
    2 3 6       1
        |
        4

would be represented with this array:

  id = [0, 5, 0, 0, 6, 5, 0]

Each root lists itself, and each non-root lists its parent.

The ID of any object `a` is given by the fixpoint of `id`:

  id[id[ ... id[b] ... ]] until it stops changing

To union `a` and `b`, set `id[self.find(a)]` to be `id[self.find(b)]`.

         5
       /   \
      0    1
    / | \
    2 3 6
        |
        4

Problem: trees can get tall, so `find` is expensive; and need to do
`find` to do `union`, so `union` is expensive too.

Solution 3: Weighting (weighted quick union)

To the previous solution add a second vector that keeps track of the
size of each tree. Initialize it to all 1s, and then whenever you
`union`, link the smaller tree below the larger one, updating the larger
one’s weight.


   (w = 5)   (w = 2)

      0         5
    / | \       |
    2 3 6       1
        |
        4

      0
   / / \ \
   2 3 6 5
       | |
       4 1

This will tend to make trees wider rather than taller. How much? Depth
is at most lg n. (How can we prove this?) So `find` is O(log n), and
Kruskal’s algorithm is O(E log E).

But we can do slightly better...

Solution 4: Path compression (WQUPC)

Whenever you find the root of an object, update id for all objects along
the path just traversed to point directly to the root. This takes no
longer (asymptotically) than just doing the `find`, but it prevents
having to re-traverse the path again in the future. This keeps the tree
almost completely flat, and result in amortized O(log* n) time for each
operation.

SUMMARY

Time for |E| operations on |V| vertices:

  Quick find     O(EV)
  Quick union    O(EV)
  Weighted QU    O(V + E log V)
  WQUPC          O((V + E) log* V)

Note that log* is nearly constant.

(Some sources claim α [inverse Ackermann] instead of log*.)
